{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample used in this study contains firms on Vietnam stock exchange from 2002 to 2019. I exclude the following observations from the sample: **utility and financial firms** , **firms with non-positive total assets or sales**, **firms that are not traded on HNX, UPCOM, or HSX**, _firms with share codes other than 10 and 11_, firms with fewer than 100 daily stock price records during a fiscal year, and firms without sufficient data to calculate the control variables described below. In addition, I follow Love et al. (2007) and remove observations that imply trade credit of longer than 1 year. The final sample consists of 129,177 firm-year observations with 13,712 unique firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockprices = pd.read_csv(\"StockPrices/CafeF.UPCOM.Upto02.10.2020.csv\")\\\n",
    "                .append(pd.read_csv(\"StockPrices/CafeF.HNX.Upto02.10.2020.csv\"))\\\n",
    "                .append(pd.read_csv(\"StockPrices/CafeF.HSX.Upto02.10.2020.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockprices.columns=[\"TICKER\",\"DATE\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"]\n",
    "stockprices = stockprices[(stockprices.DATE < 20200101) & (stockprices.DATE > 20011231)]\n",
    "stockprices.drop(columns=[\"OPEN\",\"HIGH\",\"LOW\"],inplace=True)\n",
    "stockprices.drop_duplicates(inplace=True)\n",
    "stockprices.reset_index(inplace=True,drop=True)\n",
    "stockprices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companies = pd.read_csv(\"Companies.csv\")\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquidity measures\n",
    "**The illiquidity measure proposed by Amihud (2002) is used as the primary measure of stock liquidity in this study.** This measure is widely employed in the literature and has been demonstrated to be an appropriate proxy for stock illiquidity. For example, Goyenko et al. (2009) document that among 12 proxies that use daily data, the Amihud illiquidity measure most accurately captures price impact. Hasbrouck (2009) shows that, compared to other daily proxies, the Amihud illiquidity measure is the one most strongly correlated with a TAQ-based price impact coefficient. In addition, Fong et al. (2017) find that the Amihud illiquidity measure is the best daily cost-per-dollar-volume proxy. The Amihud illiquidity measure is calculated as the daily ratio of the absolute value of stock returns to dollar volume, averaged over firm i's fiscal year t:\n",
    "\n",
    "$$\\text{Amihud Illiquidity}_{i,t}=\\dfrac{1}{D_{i,t}}\\sum_{d=1}^{D}\\dfrac{\\left |\\text{Ret}_{t,d}  \\right |}{\\text{Dollar Volume}_{i,d}}$$\n",
    "\n",
    "Where $Ret$ and $\\text{Dollar Volume}$ are the return and dollar volume of firm i on day d, respectively, and D is the total number of trading days during firm i's fiscal year t.\n",
    "\n",
    "Since the distribution of the Amihud illiquidity measure is highly skewed, I follow Edmans et al.'s (2013) approach to modify the Amihud illiquidity measure by taking the natural logarithm of (Amihud illiquidity plus one). In addition, for the convenience of interpreting the empirical results, I multiply the modified Amihud illiquidity measure by −1 and name this measure “LiqAM”. Specifically, $LiqAM$ is defined as $–ln(\\text{Amihud illiquidity} + 1)$. A higher value of $LiqAM$ is associated with a higher level of stock liquidity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks = companies[\"TICKER\"].to_frame().merge(stockprices, on='TICKER',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks['YEAR'] = filtered_stocks['DATE']//10000\n",
    "filtered_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmstat = filtered_stocks[['TICKER','YEAR']]\\\n",
    "            .groupby(by=['TICKER','YEAR'])\\\n",
    "            .size().reset_index(name='counts')\n",
    "lmstat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove firms with fewer than 100 daily stock price records during a fiscal year\n",
    "filtered_tickers = lmstat[lmstat.counts >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks= filtered_stocks.merge(filtered_tickers, on=['TICKER','YEAR'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks['VND_VOLUME'] = filtered_stocks['CLOSE']*filtered_stocks['VOLUME']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stocks.sort_values(by=['TICKER','DATE'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstgr = []\n",
    "for name,gr in filtered_stocks.groupby(['TICKER','YEAR']):\n",
    "    print(name,end=';')\n",
    "    gr['PREV_CLOSE'] = gr['CLOSE'].shift(1,fill_value=gr['CLOSE'].iloc[0])\n",
    "    gr['RET'] = np.abs(np.log(gr['CLOSE']/gr['PREV_CLOSE']))\n",
    "    gr['RET_ON_VOL'] = gr['RET']/gr[\"VND_VOLUME\"]\n",
    "    lstgr.append(gr)\n",
    "liquid_measure = pd.concat(lstgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquid_measure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amihud_Illiquidity = liquid_measure[['TICKER','YEAR','RET_ON_VOL']].groupby(['TICKER','YEAR']).agg(['sum','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amihud_Illiquidity[\"LiqAM\"] = -np.log(Amihud_Illiquidity[\"RET_ON_VOL\"][\"sum\"]/Amihud_Illiquidity[\"RET_ON_VOL\"][\"count\"]+1)\n",
    "Amihud_Illiquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amihud_Illiquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
